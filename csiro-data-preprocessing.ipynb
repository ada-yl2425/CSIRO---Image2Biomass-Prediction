{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport pickle  # 用于保存 'fitter' 对象\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T20:37:02.287062Z","iopub.execute_input":"2025-11-09T20:37:02.287357Z","iopub.status.idle":"2025-11-09T20:37:07.162958Z","shell.execute_reply.started":"2025-11-09T20:37:02.287324Z","shell.execute_reply":"2025-11-09T20:37:07.161570Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# --- 1. 配置 ---\n\n# 原始数据文件\nRAW_TRAIN_CSV = '/kaggle/input/csiro-biomass/train.csv'\n\n# 处理后数据的输出路径\nOUTPUT_DIR = \"/kaggle/working/\"\nPROCESSED_TRAIN_CSV = os.path.join(OUTPUT_DIR, 'train_processed.csv')\nSCALER_PATH = os.path.join(OUTPUT_DIR, 'scaler.pkl')\nENCODERS_PATH = os.path.join(OUTPUT_DIR, 'encoders.pkl')\n\n# 定义列组\nTARGET_COLS = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\nNUM_FEATURES = ['Pre_GSHH_NDVI', 'Height_Ave_cm']\nCAT_FEATURES = ['State', 'Species']\nTIME_FEATURE = 'Sampling_Date'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T20:37:07.165133Z","iopub.execute_input":"2025-11-09T20:37:07.165572Z","iopub.status.idle":"2025-11-09T20:37:07.175123Z","shell.execute_reply.started":"2025-11-09T20:37:07.165544Z","shell.execute_reply":"2025-11-09T20:37:07.173807Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# --- 2. 核心处理函数 ---\n\ndef process_dataframe(csv_path, is_train=True, scaler=None, encoders=None):\n    \"\"\"\n    加载并处理整个数据集（训练或测试）。\n    \n    is_train=True: \n        - 会 fit_transform 变换器\n        - 会处理目标列\n        - 会返回 (df, scaler, encoders)\n    is_train=False: \n        - 会使用传入的 scaler/encoders 进行 transform\n        - 不会处理目标列\n        - 会返回 (df)\n    \"\"\"\n    \n    # --- A. 加载与重塑 ---\n    df_long = pd.read_csv(csv_path)\n    \n    # 修正后的重塑逻辑 (使用 image_path 作为唯一ID)\n    df_wide_targets = df_long.pivot(index='image_path', columns='target_name', values='target')\n    \n    meta_cols = ['image_path', TIME_FEATURE] + CAT_FEATURES + NUM_FEATURES\n    available_meta_cols = [col for col in meta_cols if col in df_long.columns]\n    df_meta = df_long[available_meta_cols].drop_duplicates(subset='image_path').set_index('image_path')\n    \n    df_wide = df_meta.join(df_wide_targets)\n    \n    # 复制一份用于输出，避免 SettingWithCopyWarning\n    df_out = df_wide.copy()\n\n    # --- B. 处理目标 (Y) - 仅限训练集 ---\n    if is_train:\n        print(\"Processing targets (Log Transform)...\")\n        for col in TARGET_COLS:\n            df_out[f'log_{col}'] = np.log1p(df_out[col])\n    \n    # --- C. 处理时间特征 (X_time) ---\n    print(\"Processing time features (Month sin/cos)...\")\n    df_out[TIME_FEATURE] = pd.to_datetime(df_out[TIME_FEATURE])\n    df_out['Month'] = df_out[TIME_FEATURE].dt.month\n    df_out['month_sin'] = np.sin(2 * np.pi * df_out['Month'] / 12)\n    df_out['month_cos'] = np.cos(2 * np.pi * df_out['Month'] / 12)\n    \n    # --- D. 处理数值特征 (X_num) ---\n    print(\"Processing numeric features (StandardScaler)...\")\n    if is_train:\n        # 如果是训练，创建并 fit 新的 scaler\n        scaler = StandardScaler()\n        df_out[NUM_FEATURES] = scaler.fit_transform(df_out[NUM_FEATURES])\n    else:\n        # 如果是测试，使用之前 fit 好的 scaler\n        if scaler is None:\n            raise ValueError(\"Scaler must be provided for test data processing\")\n        df_out[NUM_FEATURES] = scaler.transform(df_out[NUM_FEATURES])\n\n    # --- E. 处理类别特征 (X_cat) ---\n    print(\"Processing categorical features (LabelEncoder)...\")\n    if is_train:\n        # 如果是训练，创建并 fit 新的 encoders\n        encoders = {}\n        for col in CAT_FEATURES:\n            le = LabelEncoder()\n            df_out[f'{col}_encoded'] = le.fit_transform(df_out[col])\n            encoders[col] = le\n    else:\n        # 如果是测试，使用之前 fit 好的 encoders\n        if encoders is None:\n            raise ValueError(\"Encoders must be provided for test data processing\")\n        for col in CAT_FEATURES:\n            # 使用 .transform()。如果测试集出现训练集没有的标签，会报错\n            df_out[f'{col}_encoded'] = encoders[col].transform(df_out[col])\n\n    # --- F. 返回结果 ---\n    if is_train:\n        return df_out, scaler, encoders\n    else:\n        # 确保测试集的列顺序与训练集一致\n        return df_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T20:37:07.176356Z","iopub.execute_input":"2025-11-09T20:37:07.176703Z","iopub.status.idle":"2025-11-09T20:37:07.214860Z","shell.execute_reply.started":"2025-11-09T20:37:07.176657Z","shell.execute_reply":"2025-11-09T20:37:07.213765Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# --- 3. 执行管道 ---\n\nif __name__ == \"__main__\":\n    try:\n        # 确保输出目录存在\n        os.makedirs(OUTPUT_DIR, exist_ok=True)\n        \n        # --- 处理训练数据 ---\n        print(\"--- Processing Training Data ---\")\n        train_df_processed, fitted_scaler, fitted_encoders = process_dataframe(\n            RAW_TRAIN_CSV, \n            is_train=True\n        )\n        \n        print(f\"\\nProcessed training data shape: {train_df_processed.shape}\")\n        \n        # --- 保存输出 ---\n        print(f\"Saving processed train CSV to: {PROCESSED_TRAIN_CSV}\")\n        train_df_processed.to_csv(PROCESSED_TRAIN_CSV, index=True) # index=True 保存 image_path\n        \n        print(f\"Saving scaler to: {SCALER_PATH}\")\n        with open(SCALER_PATH, 'wb') as f:\n            pickle.dump(fitted_scaler, f)\n            \n        print(f\"Saving encoders to: {ENCODERS_PATH}\")\n        with open(ENCODERS_PATH, 'wb') as f:\n            pickle.dump(fitted_encoders, f)\n            \n        print(\"\\n--- Data Processing Pipeline COMPLETED ---\")\n        \n        print(\"\\nProcessed Data Head:\")\n        print(train_df_processed.head())\n\n    except FileNotFoundError:\n        print(f\"Error: Raw data file not found at {RAW_TRAIN_CSV}\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T20:37:07.215903Z","iopub.execute_input":"2025-11-09T20:37:07.216246Z","iopub.status.idle":"2025-11-09T20:37:07.387300Z","shell.execute_reply.started":"2025-11-09T20:37:07.216216Z","shell.execute_reply":"2025-11-09T20:37:07.385921Z"}},"outputs":[{"name":"stdout","text":"--- Processing Training Data ---\nProcessing targets (Log Transform)...\nProcessing time features (Month sin/cos)...\nProcessing numeric features (StandardScaler)...\nProcessing categorical features (LabelEncoder)...\n\nProcessed training data shape: (357, 20)\nSaving processed train CSV to: /kaggle/working/train_processed.csv\nSaving scaler to: /kaggle/working/scaler.pkl\nSaving encoders to: /kaggle/working/encoders.pkl\n\n--- Data Processing Pipeline COMPLETED ---\n\nProcessed Data Head:\n                       Sampling_Date State            Species  Pre_GSHH_NDVI  \\\nimage_path                                                                     \ntrain/ID1011485656.jpg    2015-09-04   Tas    Ryegrass_Clover      -0.246319   \ntrain/ID1012260530.jpg    2015-04-01   NSW            Lucerne      -0.707060   \ntrain/ID1025234388.jpg    2015-09-01    WA  SubcloverDalkeith      -1.826004   \ntrain/ID1028611175.jpg    2015-05-18   Tas           Ryegrass       0.016962   \ntrain/ID1035947949.jpg    2015-09-11   Tas           Ryegrass      -0.772880   \n\n                        Height_Ave_cm  Dry_Clover_g  Dry_Dead_g  Dry_Green_g  \\\nimage_path                                                                     \ntrain/ID1011485656.jpg      -0.285204        0.0000     31.9984      16.2751   \ntrain/ID1012260530.jpg       0.818240        0.0000      0.0000       7.6000   \ntrain/ID1025234388.jpg      -0.642205        6.0500      0.0000       0.0000   \ntrain/ID1028611175.jpg      -0.252753        0.0000     30.9703      24.2376   \ntrain/ID1035947949.jpg      -0.398797        0.4343     23.2239      10.5261   \n\n                        Dry_Total_g    GDM_g  log_Dry_Green_g  log_Dry_Dead_g  \\\nimage_path                                                                      \ntrain/ID1011485656.jpg      48.2735  16.2750         2.849266        3.496459   \ntrain/ID1012260530.jpg       7.6000   7.6000         2.151762        0.000000   \ntrain/ID1025234388.jpg       6.0500   6.0500         0.000000        0.000000   \ntrain/ID1028611175.jpg      55.2079  24.2376         3.228335        3.464807   \ntrain/ID1035947949.jpg      34.1844  10.9605         2.444614        3.187340   \n\n                        log_Dry_Clover_g  log_GDM_g  log_Dry_Total_g  Month  \\\nimage_path                                                                    \ntrain/ID1011485656.jpg          0.000000   2.849260         3.897386      9   \ntrain/ID1012260530.jpg          0.000000   2.151762         2.151762      4   \ntrain/ID1025234388.jpg          1.953028   1.953028         1.953028      9   \ntrain/ID1028611175.jpg          0.000000   3.228335         4.029057      5   \ntrain/ID1035947949.jpg          0.360677   2.481610         3.560603      9   \n\n                        month_sin     month_cos  State_encoded  \\\nimage_path                                                       \ntrain/ID1011485656.jpg  -1.000000 -1.836970e-16              1   \ntrain/ID1012260530.jpg   0.866025 -5.000000e-01              0   \ntrain/ID1025234388.jpg  -1.000000 -1.836970e-16              3   \ntrain/ID1028611175.jpg   0.500000 -8.660254e-01              1   \ntrain/ID1035947949.jpg  -1.000000 -1.836970e-16              1   \n\n                        Species_encoded  \nimage_path                               \ntrain/ID1011485656.jpg               11  \ntrain/ID1012260530.jpg                3  \ntrain/ID1025234388.jpg               12  \ntrain/ID1028611175.jpg               10  \ntrain/ID1035947949.jpg               10  \n","output_type":"stream"}],"execution_count":4}]}