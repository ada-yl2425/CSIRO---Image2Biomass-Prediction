{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uB5tYNroaTz",
        "outputId": "f7a68b56-6346-40cf-8ddf-74f701504297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSIRO---Image2Biomass-Prediction'...\n",
            "remote: Enumerating objects: 415, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 415 (delta 15), reused 6 (delta 3), pack-reused 389 (from 4)\u001b[K\n",
            "Receiving objects: 100% (415/415), 1.02 GiB | 41.80 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "Updating files: 100% (370/370), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "CSIRO---Image2Biomass-Prediction  sample_data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "USERNAME = 'ada-yl2425'\n",
        "REPO_NAME = 'CSIRO---Image2Biomass-Prediction'\n",
        "!git clone https://{USERNAME}:{TOKEN}@github.com/{USERNAME}/{REPO_NAME}.git\n",
        "!git pull origin main\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision pandas scikit-learn pillow tqdm timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yqKgiPaVtEkT",
        "outputId": "60e3e59c-8240-47a7-a3f0-f830a9bd08de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import warnings"
      ],
      "metadata": {
        "id": "RtVfvpPytA2A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 忽略 PIL 的一些警告\n",
        "warnings.filterwarnings(\"ignore\", \"(Possibly corrupt EXIF data|Truncated File Read)\")"
      ],
      "metadata": {
        "id": "rKsGzyteuxmo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. 评估指标 (Weighted R2) ---\n",
        "def calculate_weighted_r2(y_true, y_pred, device):\n",
        "    \"\"\"\n",
        "    在原始尺度上计算全局加权 R2\n",
        "    (此版本已修复，符合官方公式)\n",
        "    y_true, y_pred: 形状为 [N, 5] 的张量 (在原始尺度上)\n",
        "    \"\"\"\n",
        "    weights = torch.tensor([0.1, 0.1, 0.1, 0.2, 0.5], dtype=torch.float32).to(device) # 形状 [5]\n",
        "\n",
        "    # --- 1. SS_res (Residual Sum of Squares) ---\n",
        "    # 按照公式: SS_res = Σ w_j * (y_j - ŷ_j)^2\n",
        "    # weights * (y_true - y_pred) ** 2 -> 广播 [5] 到 [N, 5]\n",
        "    # torch.sum(...) -> 聚合 N*5 个元素\n",
        "    ss_res = torch.sum(weights * (y_true - y_pred) ** 2)\n",
        "\n",
        "    # --- 2. SS_tot (Total Sum of Squares) ---\n",
        "\n",
        "    # [修复] 2a. 计算全局加权均值 ȳ_w (y_mean_w)\n",
        "    # ȳ_w = (Σ w_j * y_j) / (Σ w_j)\n",
        "\n",
        "    # 分子 (Numerator): Σ w_j * y_j\n",
        "    # (weights * y_true) -> 广播 [5] 到 [N, 5]\n",
        "    # torch.sum(...) -> 聚合 N*5 个元素\n",
        "    sum_weighted_values = torch.sum(weights * y_true)\n",
        "\n",
        "    # 分母 (Denominator): Σ w_j\n",
        "    # 1. 将 weights [5] 广播到 [N, 5] (N是批量大小)\n",
        "    weights_broadcasted = weights.expand_as(y_true)\n",
        "    # 2. 计算总权重和 (这等于 N * 1.0)\n",
        "    sum_of_all_weights = torch.sum(weights_broadcasted)\n",
        "\n",
        "    # 计算 ȳ_w\n",
        "    y_mean_w = sum_weighted_values / (sum_of_all_weights + 1e-6)\n",
        "\n",
        "    # [修复] 2b. 计算 SS_tot\n",
        "    # 按照公式: SS_tot = Σ w_j * (y_j - ȳ_w)^2\n",
        "    # (y_true - y_mean_w) -> 广播标量 ȳ_w 到 [N, 5]\n",
        "    # weights * (...) -> 广播 [5] 到 [N, 5]\n",
        "    ss_tot = torch.sum(weights * (y_true - y_mean_w) ** 2)\n",
        "\n",
        "    # --- 3. R2 ---\n",
        "    r2 = 1.0 - (ss_res / (ss_tot + 1e-6)) # +1e-6 防止除以零\n",
        "    return r2.item()"
      ],
      "metadata": {
        "id": "Z1IMd8iHu9PI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. 自定义数据集 ---\n",
        "class PastureDataset(Dataset):\n",
        "    \"\"\"\n",
        "    加载图像、表格数据和目标\n",
        "    \"\"\"\n",
        "    def __init__(self, df, img_dir, transforms, img_size): # <-- 增加了 img_size\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transforms = transforms\n",
        "        self.img_size = img_size  # <-- 存储 img_size\n",
        "\n",
        "        # 定义列名\n",
        "        self.numeric_cols = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'month_sin', 'month_cos']\n",
        "        self.categorical_cols = ['State_encoded', 'Species_encoded']\n",
        "\n",
        "        # 训练目标 (log scale)\n",
        "        self.log_target_cols = ['log_Dry_Green_g', 'log_Dry_Dead_g',\n",
        "                                'log_Dry_Clover_g', 'log_GDM_g', 'log_Dry_Total_g']\n",
        "\n",
        "        # 验证目标 (original scale)\n",
        "        self.orig_target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g',\n",
        "                                 'GDM_g', 'Dry_Total_g']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "\n",
        "        # 1. 加载图像\n",
        "        # 您的路径逻辑是正确的，因为 'image_path' 索引包含 'train/' 前缀\n",
        "        filename = row.name.split('/')[-1]\n",
        "        img_path = os.path.join(self.img_dir, filename)\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            image = self.transforms(image)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Error loading image {img_path}. Using a dummy image. Error: {e}\")\n",
        "            # *** 修复 ***: 使用传入的 img_size\n",
        "            image = torch.zeros((3, self.img_size, self.img_size))\n",
        "\n",
        "        # 2. 提取表格数据\n",
        "\n",
        "        # ---\n",
        "        # *** 关键修复 ***:\n",
        "        # 在 .values 之后立即使用 .astype() 强制转换类型\n",
        "        # ---\n",
        "        numeric = torch.tensor(\n",
        "            row[self.numeric_cols].values.astype(np.float32),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        categorical = torch.tensor(\n",
        "            row[self.categorical_cols].values.astype(np.int64), # 类别用 int64\n",
        "            dtype=torch.long\n",
        "        )\n",
        "\n",
        "        # 3. 提取目标 (同样应用修复)\n",
        "        log_target = torch.tensor(\n",
        "            row[self.log_target_cols].values.astype(np.float32),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        orig_target = torch.tensor(\n",
        "            row[self.orig_target_cols].values.astype(np.float32),\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'image': image,\n",
        "            'numeric': numeric,\n",
        "            'categorical': categorical,\n",
        "            'log_target': log_target,\n",
        "            'orig_target': orig_target\n",
        "        }"
      ],
      "metadata": {
        "id": "_DxsWaHI50S4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. 训练和验证循环 ---\n",
        "\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch in tqdm(loader, desc=\"Training\"):\n",
        "        # 移动数据到设备\n",
        "        image = batch['image'].to(device)\n",
        "        numeric = batch['numeric'].to(device)\n",
        "        categorical = batch['categorical'].to(device)\n",
        "        log_target = batch['log_target'].to(device)\n",
        "\n",
        "        # 梯度清零\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 前向传播\n",
        "        pred = model(image, numeric, categorical)\n",
        "\n",
        "        # 计算损失 (在 log 尺度上)\n",
        "        loss = criterion(pred, log_target)\n",
        "\n",
        "        # 反向传播\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "def validate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    all_preds_orig = []\n",
        "    all_targets_orig = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Validating\"):\n",
        "            image = batch['image'].to(device)\n",
        "            numeric = batch['numeric'].to(device)\n",
        "            categorical = batch['categorical'].to(device)\n",
        "            log_target = batch['log_target'].to(device)\n",
        "            orig_target = batch['orig_target'].to(device)\n",
        "\n",
        "            # 预测 (log 尺度)\n",
        "            pred_log = model(image, numeric, categorical)\n",
        "\n",
        "            # 计算验证损失 (log 尺度)\n",
        "            loss = criterion(pred_log, log_target)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            # 转换回原始尺度\n",
        "            pred_orig = torch.expm1(pred_log)\n",
        "\n",
        "            all_preds_orig.append(pred_orig)\n",
        "            all_targets_orig.append(orig_target)\n",
        "\n",
        "    # 拼接所有批次的结果\n",
        "    all_preds_orig = torch.cat(all_preds_orig, dim=0)\n",
        "    all_targets_orig = torch.cat(all_targets_orig, dim=0)\n",
        "\n",
        "    # 计算 R2 (原始尺度)\n",
        "    val_r2 = calculate_weighted_r2(all_targets_orig, all_preds_orig, device)\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(loader)\n",
        "\n",
        "    return avg_val_loss, val_r2\n"
      ],
      "metadata": {
        "id": "ZqcjtP-5vTNp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# --- 4. 主函数 ---\n",
        "def main(args):\n",
        "    # 设置设备\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # 加载数据\n",
        "    df = pd.read_csv(args.data_csv, index_col='image_path')\n",
        "\n",
        "    # 获取类别数量 (用于 Embedding)\n",
        "    num_states = df['State_encoded'].nunique()\n",
        "    num_species = df['Species_encoded'].nunique()\n",
        "    print(f\"Found {num_states} states and {num_species} species.\")\n",
        "\n",
        "    # 拆分训练/验证集\n",
        "    train_df, val_df = train_test_split(df, test_size=args.val_split, random_state=42)\n",
        "\n",
        "    # 图像预处理\n",
        "    # 区分训练和验证的变换\n",
        "\n",
        "    # 训练集使用强数据增强\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((args.img_size, args.img_size)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转\n",
        "        transforms.RandomVerticalFlip(p=0.5),   # 随机垂直翻转\n",
        "        transforms.RandomRotation(30),           # 随机旋转 (-30 到 30 度)\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # 随机调整颜色\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # 验证集不使用增强，只做 Resize 和 Normalize\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((args.img_size, args.img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # ... (跳过拆分) ...\n",
        "\n",
        "    # 创建 Datasets 和 DataLoaders\n",
        "    # *** 注意：这里要用不同的变换 ***\n",
        "    train_dataset = PastureDataset(train_df, args.img_dir, train_transforms, args.img_size)\n",
        "    val_dataset = PastureDataset(val_df, args.img_dir, val_transforms, args.img_size)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
        "\n",
        "    # 初始化模型、损失和优化器\n",
        "    model = TeacherModel(num_states, num_species).to(device)\n",
        "    criterion = WeightedMSELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=5e-3)\n",
        "\n",
        "    # 学习率调度器\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5, factor=0.1)\n",
        "\n",
        "    # 训练循环\n",
        "    best_val_r2 = -float('inf')\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        print(f\"--- Epoch {epoch+1}/{args.epochs} ---\")\n",
        "\n",
        "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_r2 = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val R2: {val_r2:.4f}\")\n",
        "\n",
        "        # 更新学习率\n",
        "        scheduler.step(val_r2)\n",
        "\n",
        "        # 保存最佳模型\n",
        "        if val_r2 > best_val_r2:\n",
        "            best_val_r2 = val_r2\n",
        "            torch.save(model.state_dict(), os.path.join(args.output_dir, \"best_teacher_model.pth\"))\n",
        "            print(f\"New best model saved with R2: {best_val_r2:.4f}\")\n",
        "\n",
        "    print(f\"Training complete. Best Validation R2: {best_val_r2:.4f}\")\n",
        "    print(f\"Best model saved to {os.path.join(args.output_dir, 'best_teacher_model.pth')}\")\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "5eXR-z3WwOmc",
        "outputId": "550e4361-0b8e-47e2-c429-b4cd724aaacb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# --- 4. 主函数 ---\\ndef main(args):\\n    # 设置设备\\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\\n    print(f\"Using device: {device}\")\\n    \\n    # 加载数据\\n    df = pd.read_csv(args.data_csv, index_col=\\'image_path\\')\\n    \\n    # 获取类别数量 (用于 Embedding)\\n    num_states = df[\\'State_encoded\\'].nunique()\\n    num_species = df[\\'Species_encoded\\'].nunique()\\n    print(f\"Found {num_states} states and {num_species} species.\")\\n    \\n    # 拆分训练/验证集\\n    train_df, val_df = train_test_split(df, test_size=args.val_split, random_state=42)\\n    \\n    # 图像预处理\\n    # 区分训练和验证的变换\\n    \\n    # 训练集使用强数据增强\\n    train_transforms = transforms.Compose([\\n        transforms.Resize((args.img_size, args.img_size)),\\n        transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转\\n        transforms.RandomVerticalFlip(p=0.5),   # 随机垂直翻转\\n        transforms.RandomRotation(30),           # 随机旋转 (-30 到 30 度)\\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # 随机调整颜色\\n        transforms.ToTensor(),\\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n    ])\\n    \\n    # 验证集不使用增强，只做 Resize 和 Normalize\\n    val_transforms = transforms.Compose([\\n        transforms.Resize((args.img_size, args.img_size)),\\n        transforms.ToTensor(),\\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\\n    ])\\n\\n    # ... (跳过拆分) ...\\n    \\n    # 创建 Datasets 和 DataLoaders\\n    # *** 注意：这里要用不同的变换 ***\\n    train_dataset = PastureDataset(train_df, args.img_dir, train_transforms, args.img_size)\\n    val_dataset = PastureDataset(val_df, args.img_dir, val_transforms, args.img_size)\\n    \\n    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\\n    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\\n    \\n    # 初始化模型、损失和优化器\\n    model = TeacherModel(num_states, num_species).to(device)\\n    criterion = WeightedMSELoss()\\n    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=5e-3)\\n    \\n    # 学习率调度器\\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \\'max\\', patience=5, factor=0.1)\\n    \\n    # 训练循环\\n    best_val_r2 = -float(\\'inf\\')\\n    \\n    for epoch in range(args.epochs):\\n        print(f\"--- Epoch {epoch+1}/{args.epochs} ---\")\\n        \\n        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\\n        val_loss, val_r2 = validate(model, val_loader, criterion, device)\\n        \\n        print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val R2: {val_r2:.4f}\")\\n        \\n        # 更新学习率\\n        scheduler.step(val_r2)\\n        \\n        # 保存最佳模型\\n        if val_r2 > best_val_r2:\\n            best_val_r2 = val_r2\\n            torch.save(model.state_dict(), os.path.join(args.output_dir, \"best_teacher_model.pth\"))\\n            print(f\"New best model saved with R2: {best_val_r2:.4f}\")\\n            \\n    print(f\"Training complete. Best Validation R2: {best_val_r2:.4f}\")\\n    print(f\"Best model saved to {os.path.join(args.output_dir, \\'best_teacher_model.pth\\')}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. 主函数 (已更新为 5-Fold CV + Early Stopping) ---\n",
        "def main(args):\n",
        "    # 设置设备\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # 加载数据\n",
        "    df = pd.read_csv(args.data_csv, index_col='image_path')\n",
        "\n",
        "    # 获取类别数量 (用于 Embedding)\n",
        "    num_states = df['State_encoded'].nunique()\n",
        "    num_species = df['Species_encoded'].nunique()\n",
        "    print(f\"Found {num_states} states and {num_species} species.\")\n",
        "\n",
        "    # 图像预处理\n",
        "    # 训练集使用强数据增强\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.Resize((args.img_size, args.img_size)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5), # 随机水平翻转\n",
        "        transforms.RandomVerticalFlip(p=0.5),   # 随机垂直翻转\n",
        "        transforms.RandomRotation(30),           # 随机旋转 (-30 到 30 度)\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # 随机调整颜色\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # 验证集不使用增强，只做 Resize 和 Normalize\n",
        "    val_transforms = transforms.Compose([\n",
        "        transforms.Resize((args.img_size, args.img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "    # --- K-Fold Cross-Validation 设置 ---\n",
        "    N_SPLITS = 5\n",
        "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
        "\n",
        "    all_fold_best_r2 = [] # 存储每一折的 R2 分数\n",
        "\n",
        "    # --- K-Fold 训练循环 ---\n",
        "    for fold, (train_indices, val_indices) in enumerate(kf.split(df)):\n",
        "        print(f\"========== FOLD {fold + 1}/{N_SPLITS} ==========\")\n",
        "\n",
        "        # 1. 为当前折创建数据\n",
        "        train_df = df.iloc[train_indices]\n",
        "        val_df = df.iloc[val_indices]\n",
        "\n",
        "        # 2. 创建 Datasets 和 DataLoaders\n",
        "        train_dataset = PastureDataset(train_df, args.img_dir, train_transforms, args.img_size)\n",
        "        val_dataset = PastureDataset(val_df, args.img_dir, val_transforms, args.img_size)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
        "\n",
        "        # 3. !! 为当前折重新初始化模型、损失和优化器 !!\n",
        "        model = TeacherModel(num_states, num_species).to(device)\n",
        "        criterion = WeightedMSELoss()\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=5e-4)\n",
        "\n",
        "        # 学习率调度器\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=7, factor=0.1)\n",
        "\n",
        "        # 4. 训练循环 (针对当前折)\n",
        "        best_val_r2 = -float('inf')\n",
        "\n",
        "        # --- [新] 早停变量 ---\n",
        "        patience_counter = 0\n",
        "        # -------------------------\n",
        "\n",
        "        for epoch in range(args.epochs):\n",
        "            print(f\"--- Fold {fold+1}, Epoch {epoch+1}/{args.epochs} ---\")\n",
        "\n",
        "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "            val_loss, val_r2 = validate(model, val_loader, criterion, device)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val R2: {val_r2:.4f}\")\n",
        "\n",
        "            # 更新学习率\n",
        "            scheduler.step(val_r2)\n",
        "\n",
        "            # --- [新] 早停和模型保存逻辑 ---\n",
        "            if val_r2 > best_val_r2:\n",
        "                best_val_r2 = val_r2\n",
        "                patience_counter = 0 # 重置耐心\n",
        "\n",
        "                # 保存最佳模型 (针对当前折)\n",
        "                save_path = os.path.join(args.output_dir, f\"best_teacher_model_fold_{fold+1}.pth\")\n",
        "                torch.save(model.state_dict(), save_path)\n",
        "                print(f\"New best model for fold {fold+1} saved with R2: {best_val_r2:.4f}\")\n",
        "            else:\n",
        "                patience_counter += 1 # 增加耐心\n",
        "                print(f\"No improvement. Patience: {patience_counter}/{args.early_stopping_patience}\")\n",
        "\n",
        "            # 检查是否触发早停\n",
        "            if patience_counter >= args.early_stopping_patience:\n",
        "                print(f\"--- Early stopping triggered at epoch {epoch+1} ---\")\n",
        "                break # 跳出当前 fold 的 epoch 循环\n",
        "            # -----------------------------------\n",
        "\n",
        "        print(f\"Fold {fold+1} complete. Best Validation R2: {best_val_r2:.4f}\")\n",
        "        all_fold_best_r2.append(best_val_r2)\n",
        "        print(\"=============================\\n\")\n",
        "\n",
        "    # --- K-Fold 结束后，计算并打印平均 R2 ---\n",
        "    print(\"\\n--- K-Fold Cross-Validation Complete ---\")\n",
        "    print(f\"R2 scores for each fold: {all_fold_best_r2}\")\n",
        "    print(f\"Average R2: {np.mean(all_fold_best_r2):.4f}\")\n",
        "    print(f\"Std Dev R2: {np.std(all_fold_best_r2):.4f}\")"
      ],
      "metadata": {
        "id": "YOFG9A4k_brg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os # 确保导入 os\n",
        "import argparse # 确保导入 argparse\n",
        "\n",
        "project_root = '/content/CSIRO---Image2Biomass-Prediction'\n",
        "if project_root not in sys.path:\n",
        "    sys.path.append(project_root)\n",
        "\n",
        "# 导入您的模块\n",
        "from KnowledgeDistillation.teacher_model import TeacherModel\n",
        "from KnowledgeDistillation.loss import WeightedMSELoss\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Train Teacher Model\")\n",
        "\n",
        "    # 使用 os.path.join 和您的 project_root 变量来构建绝对路径\n",
        "\n",
        "    parser.add_argument('--data_csv', type=str,\n",
        "                        default=os.path.join(project_root, 'csiro-biomass/preprocessing_output/train_processed.csv'),\n",
        "                        help='Path to the processed training CSV file')\n",
        "\n",
        "    parser.add_argument('--img_dir', type=str,\n",
        "                        default=os.path.join(project_root, 'csiro-biomass/train'),\n",
        "                        help='Path to the directory containing training images')\n",
        "\n",
        "    # 指定一个明确的输出目录\n",
        "    output_path = os.path.join(project_root, 'KnowledgeDistillation/teacher_model_output')\n",
        "    parser.add_argument('--output_dir', type=str,\n",
        "                        default=output_path,\n",
        "                        help='Directory to save the best model')\n",
        "\n",
        "    # --------------------------\n",
        "\n",
        "    # 训练超参数\n",
        "    parser.add_argument('--img_size', type=int, default=240, # 建议 B1 使用 240\n",
        "                        help='Image size for the model')\n",
        "    parser.add_argument('--lr', type=float, default=1e-4,\n",
        "                        help='Initial learning rate (1e-4 is good for fine-tuning)')\n",
        "    parser.add_argument('--batch_size', type=int, default=16,\n",
        "                        help='Batch size (use 8 or 16 for small datasets)')\n",
        "    parser.add_argument('--epochs', type=int, default=100,\n",
        "                        help='Number of training epochs')\n",
        "    parser.add_argument('--val_split', type=float, default=0.2,\n",
        "                        help='Validation split fraction')\n",
        "    parser.add_argument('--num_workers', type=int, default=2,\n",
        "                        help='Number of workers for DataLoader')\n",
        "\n",
        "    # --- [新] 早停参数 ---\n",
        "    parser.add_argument('--early_stopping_patience', type=int, default=10,\n",
        "                        help='Patience for early stopping (e.g., 10 epochs)')\n",
        "    # -------------------------\n",
        "\n",
        "    # 传入一个空列表，告诉 argparse \"不要读取 sys.argv\"\n",
        "    args = parser.parse_args(args=[])\n",
        "\n",
        "    # 确保输出目录存在\n",
        "    # args.output_dir 现在是绝对路径\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "    print(f\"Model output will be saved to: {args.output_dir}\")\n",
        "    print(f\"Reading data from: {args.data_csv}\")\n",
        "\n",
        "    main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66SbvqjK_k-k",
        "outputId": "a8ec8f70-41dc-407e-e57e-a08bb1112bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output will be saved to: /content/CSIRO---Image2Biomass-Prediction/KnowledgeDistillation/teacher_model_output\n",
            "Reading data from: /content/CSIRO---Image2Biomass-Prediction/csiro-biomass/preprocessing_output/train_processed.csv\n",
            "Using device: cuda\n",
            "Found 4 states and 15 species.\n",
            "========== FOLD 1/5 ==========\n",
            "--- Fold 1, Epoch 1/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.04it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 2.2998 | Val Loss: 2.1457 | Val R2: -1.6525\n",
            "New best model for fold 1 saved with R2: -1.6525\n",
            "--- Fold 1, Epoch 2/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:09<00:00,  1.93it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  1.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss: 2.2090 | Val Loss: 2.0847 | Val R2: -1.6420\n",
            "New best model for fold 1 saved with R2: -1.6420\n",
            "--- Fold 1, Epoch 3/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss: 2.0773 | Val Loss: 1.9274 | Val R2: -1.6150\n",
            "New best model for fold 1 saved with R2: -1.6150\n",
            "--- Fold 1, Epoch 4/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss: 1.9723 | Val Loss: 1.8019 | Val R2: -1.5881\n",
            "New best model for fold 1 saved with R2: -1.5881\n",
            "--- Fold 1, Epoch 5/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 1.8186 | Val Loss: 1.6476 | Val R2: -1.5490\n",
            "New best model for fold 1 saved with R2: -1.5490\n",
            "--- Fold 1, Epoch 6/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:09<00:00,  2.00it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss: 1.6816 | Val Loss: 1.4556 | Val R2: -1.4753\n",
            "New best model for fold 1 saved with R2: -1.4753\n",
            "--- Fold 1, Epoch 7/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss: 1.5680 | Val Loss: 1.3353 | Val R2: -1.4199\n",
            "New best model for fold 1 saved with R2: -1.4199\n",
            "--- Fold 1, Epoch 8/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss: 1.4671 | Val Loss: 1.1924 | Val R2: -1.3535\n",
            "New best model for fold 1 saved with R2: -1.3535\n",
            "--- Fold 1, Epoch 9/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss: 1.3139 | Val Loss: 1.0699 | Val R2: -1.2567\n",
            "New best model for fold 1 saved with R2: -1.2567\n",
            "--- Fold 1, Epoch 10/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.00it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss: 1.1839 | Val Loss: 0.9591 | Val R2: -1.1750\n",
            "New best model for fold 1 saved with R2: -1.1750\n",
            "--- Fold 1, Epoch 11/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train Loss: 1.0557 | Val Loss: 0.8436 | Val R2: -1.0798\n",
            "New best model for fold 1 saved with R2: -1.0798\n",
            "--- Fold 1, Epoch 12/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train Loss: 0.9159 | Val Loss: 0.7371 | Val R2: -0.9799\n",
            "New best model for fold 1 saved with R2: -0.9799\n",
            "--- Fold 1, Epoch 13/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train Loss: 0.7758 | Val Loss: 0.6165 | Val R2: -0.8005\n",
            "New best model for fold 1 saved with R2: -0.8005\n",
            "--- Fold 1, Epoch 14/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.03it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train Loss: 0.6541 | Val Loss: 0.5856 | Val R2: -0.8580\n",
            "No improvement. Patience: 1/10\n",
            "--- Fold 1, Epoch 15/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train Loss: 0.5239 | Val Loss: 0.4454 | Val R2: -0.5505\n",
            "New best model for fold 1 saved with R2: -0.5505\n",
            "--- Fold 1, Epoch 16/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Train Loss: 0.4494 | Val Loss: 0.3627 | Val R2: -0.4475\n",
            "New best model for fold 1 saved with R2: -0.4475\n",
            "--- Fold 1, Epoch 17/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.03it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Train Loss: 0.3710 | Val Loss: 0.3022 | Val R2: -0.3253\n",
            "New best model for fold 1 saved with R2: -0.3253\n",
            "--- Fold 1, Epoch 18/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Train Loss: 0.2865 | Val Loss: 0.2274 | Val R2: -0.0775\n",
            "New best model for fold 1 saved with R2: -0.0775\n",
            "--- Fold 1, Epoch 19/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.03it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Train Loss: 0.2508 | Val Loss: 0.1880 | Val R2: 0.0996\n",
            "New best model for fold 1 saved with R2: 0.0996\n",
            "--- Fold 1, Epoch 20/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Train Loss: 0.2422 | Val Loss: 0.1782 | Val R2: 0.1410\n",
            "New best model for fold 1 saved with R2: 0.1410\n",
            "--- Fold 1, Epoch 21/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Train Loss: 0.2099 | Val Loss: 0.1703 | Val R2: 0.1695\n",
            "New best model for fold 1 saved with R2: 0.1695\n",
            "--- Fold 1, Epoch 22/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.00it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Train Loss: 0.1892 | Val Loss: 0.1665 | Val R2: -0.0085\n",
            "No improvement. Patience: 1/10\n",
            "--- Fold 1, Epoch 23/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Train Loss: 0.1861 | Val Loss: 0.1452 | Val R2: 0.2810\n",
            "New best model for fold 1 saved with R2: 0.2810\n",
            "--- Fold 1, Epoch 24/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Train Loss: 0.1726 | Val Loss: 0.1146 | Val R2: 0.3973\n",
            "New best model for fold 1 saved with R2: 0.3973\n",
            "--- Fold 1, Epoch 25/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Train Loss: 0.1682 | Val Loss: 0.1294 | Val R2: 0.4044\n",
            "New best model for fold 1 saved with R2: 0.4044\n",
            "--- Fold 1, Epoch 26/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.03it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Train Loss: 0.1542 | Val Loss: 0.1315 | Val R2: 0.3152\n",
            "No improvement. Patience: 1/10\n",
            "--- Fold 1, Epoch 27/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: Train Loss: 0.1414 | Val Loss: 0.1379 | Val R2: 0.2830\n",
            "No improvement. Patience: 2/10\n",
            "--- Fold 1, Epoch 28/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: Train Loss: 0.1482 | Val Loss: 0.1249 | Val R2: 0.4542\n",
            "New best model for fold 1 saved with R2: 0.4542\n",
            "--- Fold 1, Epoch 29/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.00it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: Train Loss: 0.1435 | Val Loss: 0.1042 | Val R2: 0.4350\n",
            "No improvement. Patience: 1/10\n",
            "--- Fold 1, Epoch 30/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.01it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Train Loss: 0.1352 | Val Loss: 0.1155 | Val R2: 0.2768\n",
            "No improvement. Patience: 2/10\n",
            "--- Fold 1, Epoch 31/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.02it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: Train Loss: 0.1401 | Val Loss: 0.1029 | Val R2: 0.4887\n",
            "New best model for fold 1 saved with R2: 0.4887\n",
            "--- Fold 1, Epoch 32/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: Train Loss: 0.1492 | Val Loss: 0.1079 | Val R2: 0.3474\n",
            "No improvement. Patience: 1/10\n",
            "--- Fold 1, Epoch 33/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.04it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: Train Loss: 0.1323 | Val Loss: 0.1063 | Val R2: 0.3763\n",
            "No improvement. Patience: 2/10\n",
            "--- Fold 1, Epoch 34/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:09<00:00,  1.99it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: Train Loss: 0.1354 | Val Loss: 0.1070 | Val R2: 0.3581\n",
            "No improvement. Patience: 3/10\n",
            "--- Fold 1, Epoch 35/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.00it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: Train Loss: 0.1195 | Val Loss: 0.0967 | Val R2: 0.5341\n",
            "New best model for fold 1 saved with R2: 0.5341\n",
            "--- Fold 1, Epoch 36/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.00it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: Train Loss: 0.1167 | Val Loss: 0.0923 | Val R2: 0.5441\n",
            "New best model for fold 1 saved with R2: 0.5441\n",
            "--- Fold 1, Epoch 37/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 18/18 [00:08<00:00,  2.00it/s]\n",
            "Validating: 100%|██████████| 5/5 [00:02<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: Train Loss: 0.1142 | Val Loss: 0.1056 | Val R2: 0.3269\n",
            "No improvement. Patience: 1/10\n",
            "--- Fold 1, Epoch 38/100 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  17%|█▋        | 3/18 [00:02<00:09,  1.58it/s]"
          ]
        }
      ]
    }
  ]
}