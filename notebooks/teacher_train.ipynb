{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639162df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:07:07.893583Z",
     "iopub.status.busy": "2025-12-01T10:07:07.893255Z",
     "iopub.status.idle": "2025-12-01T10:08:25.819311Z",
     "shell.execute_reply": "2025-12-01T10:08:25.818545Z"
    },
    "id": "yqKgiPaVtEkT",
    "outputId": "60e3e59c-8240-47a7-a3f0-f830a9bd08de",
    "papermill": {
     "duration": 77.93707,
     "end_time": "2025-12-01T10:08:25.820748",
     "exception": false,
     "start_time": "2025-12-01T10:07:07.883678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision pandas scikit-learn pillow tqdm timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7075456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:08:25.889112Z",
     "iopub.status.busy": "2025-12-01T10:08:25.888649Z",
     "iopub.status.idle": "2025-12-01T10:08:35.997488Z",
     "shell.execute_reply": "2025-12-01T10:08:35.996877Z"
    },
    "id": "RtVfvpPytA2A",
    "papermill": {
     "duration": 10.1442,
     "end_time": "2025-12-01T10:08:35.998812",
     "exception": false,
     "start_time": "2025-12-01T10:08:25.854612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "import argparse \n",
    "\n",
    "project_root = 'CSIRO---Image2Biomass-Prediction'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from KnowledgeDistillation.teacher_model import TeacherModel\n",
    "from KnowledgeDistillation.loss import WeightedMSELoss, calculate_weighted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d153c1a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:08:36.067410Z",
     "iopub.status.busy": "2025-12-01T10:08:36.067027Z",
     "iopub.status.idle": "2025-12-01T10:08:36.070710Z",
     "shell.execute_reply": "2025-12-01T10:08:36.070147Z"
    },
    "id": "rKsGzyteuxmo",
    "papermill": {
     "duration": 0.038921,
     "end_time": "2025-12-01T10:08:36.071712",
     "exception": false,
     "start_time": "2025-12-01T10:08:36.032791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", \"(Possibly corrupt EXIF data|Truncated File Read)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8189aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:08:36.214952Z",
     "iopub.status.busy": "2025-12-01T10:08:36.214730Z",
     "iopub.status.idle": "2025-12-01T10:08:36.222280Z",
     "shell.execute_reply": "2025-12-01T10:08:36.221778Z"
    },
    "id": "_DxsWaHI50S4",
    "papermill": {
     "duration": 0.044809,
     "end_time": "2025-12-01T10:08:36.223298",
     "exception": false,
     "start_time": "2025-12-01T10:08:36.178489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PastureDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, img_dir, transforms, img_size): \n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.img_size = img_size  \n",
    "\n",
    "        # 定义列名\n",
    "        self.numeric_cols = ['Pre_GSHH_NDVI', 'Height_Ave_cm', 'month_sin', 'month_cos']\n",
    "        self.categorical_cols = ['State_encoded', 'Species_encoded']\n",
    "\n",
    "        # 训练目标 (log scale)\n",
    "        self.log_target_cols = ['log_Dry_Green_g', 'log_Dry_Dead_g',\n",
    "                                'log_Dry_Clover_g', 'log_GDM_g', 'log_Dry_Total_g']\n",
    "\n",
    "        # 验证目标 (original scale)\n",
    "        self.orig_target_cols = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g',\n",
    "                                 'GDM_g', 'Dry_Total_g']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # 1. 加载图像\n",
    "        filename = row.name.split('/')[-1]\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            image = self.transforms(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error loading image {img_path}. Using a dummy image. Error: {e}\")\n",
    "            image = torch.zeros((3, self.img_size, self.img_size))\n",
    "\n",
    "        # 2. 提取表格数据\n",
    "        numeric = torch.tensor(\n",
    "            row[self.numeric_cols].values.astype(np.float32),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        categorical = torch.tensor(\n",
    "            row[self.categorical_cols].values.astype(np.int64), \n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        # 3. 提取目标\n",
    "        log_target = torch.tensor(\n",
    "            row[self.log_target_cols].values.astype(np.float32),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        orig_target = torch.tensor(\n",
    "            row[self.orig_target_cols].values.astype(np.float32),\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'numeric': numeric,\n",
    "            'categorical': categorical,\n",
    "            'log_target': log_target,\n",
    "            'orig_target': orig_target\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35bca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:08:36.300377Z",
     "iopub.status.busy": "2025-12-01T10:08:36.300138Z",
     "iopub.status.idle": "2025-12-01T10:08:36.307085Z",
     "shell.execute_reply": "2025-12-01T10:08:36.306581Z"
    },
    "id": "ZqcjtP-5vTNp",
    "papermill": {
     "duration": 0.046618,
     "end_time": "2025-12-01T10:08:36.308076",
     "exception": false,
     "start_time": "2025-12-01T10:08:36.261458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 3. 训练和验证循环 ---\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        # 移动数据到设备\n",
    "        image = batch['image'].to(device)\n",
    "        numeric = batch['numeric'].to(device)\n",
    "        categorical = batch['categorical'].to(device)\n",
    "        log_target = batch['log_target'].to(device)\n",
    "\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播\n",
    "        pred = model(image, numeric, categorical)\n",
    "\n",
    "        # 计算损失 (在 log 尺度上)\n",
    "        loss = criterion(pred, log_target)\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    all_preds_orig = []\n",
    "    all_targets_orig = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validating\"):\n",
    "            image = batch['image'].to(device)\n",
    "            numeric = batch['numeric'].to(device)\n",
    "            categorical = batch['categorical'].to(device)\n",
    "            log_target = batch['log_target'].to(device)\n",
    "            orig_target = batch['orig_target'].to(device)\n",
    "\n",
    "            # 预测 (log 尺度)\n",
    "            pred_log = model(image, numeric, categorical)\n",
    "\n",
    "            # 计算验证损失 (log 尺度)\n",
    "            loss = criterion(pred_log, log_target)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # 转换回原始尺度\n",
    "            pred_orig = torch.expm1(pred_log)\n",
    "\n",
    "            all_preds_orig.append(pred_orig)\n",
    "            all_targets_orig.append(orig_target)\n",
    "\n",
    "    # 拼接所有批次的结果\n",
    "    all_preds_orig = torch.cat(all_preds_orig, dim=0)\n",
    "    all_targets_orig = torch.cat(all_targets_orig, dim=0)\n",
    "\n",
    "    # 计算 R2 (原始尺度)\n",
    "    val_r2 = calculate_weighted_r2(all_targets_orig, all_preds_orig, device)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(loader)\n",
    "\n",
    "    return avg_val_loss, val_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2886cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:08:36.384790Z",
     "iopub.status.busy": "2025-12-01T10:08:36.384560Z",
     "iopub.status.idle": "2025-12-01T10:08:36.398715Z",
     "shell.execute_reply": "2025-12-01T10:08:36.398006Z"
    },
    "id": "YOFG9A4k_brg",
    "papermill": {
     "duration": 0.049833,
     "end_time": "2025-12-01T10:08:36.399804",
     "exception": false,
     "start_time": "2025-12-01T10:08:36.349971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    df = pd.read_csv(args.data_csv, index_col='image_path')\n",
    "\n",
    "    num_states = df['State_encoded'].nunique()\n",
    "    num_species = df['Species_encoded'].nunique()\n",
    "    print(f\"Found {num_states} states and {num_species} species.\")\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((args.img_size, args.img_size)),\n",
    "        \n",
    "        # --- 1. 几何变换 ---\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(90),\n",
    "        \n",
    "        # 仿射变换：平移 和 错切\n",
    "        transforms.RandomAffine(\n",
    "            degrees=0,\n",
    "            translate=(0.15, 0.15),  # 随机平移 15%\n",
    "            shear=15                 # 随机错切 15 度\n",
    "        ), \n",
    "\n",
    "        # --- 2. 颜色变换 (模拟不同光照/季节) ---\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.3,\n",
    "            contrast=0.3, \n",
    "            saturation=0.3, \n",
    "            hue=0.1\n",
    "        ), \n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # 验证集不使用增强，只做 Resize 和 Normalize\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((args.img_size, args.img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # --- K-Fold Cross-Validation 设置 ---\n",
    "    N_SPLITS = 5\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "    all_fold_best_r2 = [] # 存储每一折的 R2 分数\n",
    "\n",
    "    # --- K-Fold 训练循环 ---\n",
    "    for fold, (train_indices, val_indices) in enumerate(kf.split(df)):\n",
    "        print(f\"========== FOLD {fold + 1}/{N_SPLITS} ==========\")\n",
    "\n",
    "        # 1. 为当前折创建数据\n",
    "        train_df = df.iloc[train_indices]\n",
    "        val_df = df.iloc[val_indices]\n",
    "\n",
    "        # 2. 创建 Datasets 和 DataLoaders\n",
    "        train_dataset = PastureDataset(train_df, args.img_dir, train_transforms, args.img_size)\n",
    "        val_dataset = PastureDataset(val_df, args.img_dir, val_transforms, args.img_size)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
    "\n",
    "        # 3. 为当前折重新初始化模型、损失和优化器\n",
    "        model = TeacherModel(num_states, num_species).to(device)\n",
    "        criterion = WeightedMSELoss()\n",
    "\n",
    "        # 4. 设置差分学习率 (Differential LRs)\n",
    "        \n",
    "        # 1. 定义哪些模块属于“Head”（从零开始学）\n",
    "        head_param_names = [\n",
    "            'tab_mlp',\n",
    "            'state_embedding',\n",
    "            'species_embedding',\n",
    "            'img_kv_projector',  \n",
    "            'tab_q_projector',   \n",
    "            'cross_attn',        \n",
    "            'attn_norm',         \n",
    "            'fusion_head'\n",
    "        ]\n",
    "        \n",
    "        head_params = []\n",
    "        backbone_params = []\n",
    "\n",
    "        # 2. 将所有可训练参数 (requires_grad=True) 分配到两组\n",
    "        for name, param in model.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "                \n",
    "            is_head = False\n",
    "            for head_name in head_param_names:\n",
    "                if name.startswith(head_name):\n",
    "                    head_params.append(param)\n",
    "                    is_head = True\n",
    "                    break\n",
    "            \n",
    "            if not is_head:\n",
    "                backbone_params.append(param)\n",
    "\n",
    "        # 3. 创建参数组\n",
    "        # 主干 (Backbone) 使用基础 LR\n",
    "        # 头部 (Head) 使用 10 倍的基础 LR\n",
    "        param_groups = [\n",
    "            {'params': backbone_params, 'lr': args.lr}, \n",
    "            {'params': head_params, 'lr': args.lr * 10}  \n",
    "        ]\n",
    "\n",
    "        # 4. 为当前折重新初始化模型、损失和优化器\n",
    "        optimizer = optim.AdamW(param_groups, \n",
    "                              lr=args.lr, \n",
    "                              weight_decay=1e-3) \n",
    "\n",
    "        # 学习率调度器\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=7, factor=0.1)\n",
    "\n",
    "        # 5. 训练循环 (针对当前折)\n",
    "        best_val_r2 = -float('inf')\n",
    "\n",
    "        # --- 早停变量 ---\n",
    "        patience_counter = 0\n",
    "        # -------------------------\n",
    "\n",
    "        for epoch in range(args.epochs):\n",
    "            print(f\"--- Fold {fold+1}, Epoch {epoch+1}/{args.epochs} ---\")\n",
    "\n",
    "            train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            val_loss, val_r2 = validate(model, val_loader, criterion, device)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val R2: {val_r2:.4f}\")\n",
    "\n",
    "            # 更新学习率\n",
    "            scheduler.step(val_r2)\n",
    "\n",
    "            # --- 早停和模型保存逻辑 ---\n",
    "            if val_r2 > best_val_r2:\n",
    "                best_val_r2 = val_r2\n",
    "                patience_counter = 0 # 重置耐心\n",
    "\n",
    "                # 保存最佳模型 (针对当前折)\n",
    "                save_path = os.path.join(args.output_dir, f\"best_teacher_model_fold_{fold+1}.pth\")\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                print(f\"New best model for fold {fold+1} saved with R2: {best_val_r2:.4f}\")\n",
    "            else:\n",
    "                patience_counter += 1 # 增加耐心\n",
    "                print(f\"No improvement. Patience: {patience_counter}/{args.early_stopping_patience}\")\n",
    "\n",
    "            # 检查是否触发早停\n",
    "            if patience_counter >= args.early_stopping_patience:\n",
    "                print(f\"--- Early stopping triggered at epoch {epoch+1} ---\")\n",
    "                break # 跳出当前 fold 的 epoch 循环\n",
    "            # -----------------------------------\n",
    "\n",
    "        print(f\"Fold {fold+1} complete. Best Validation R2: {best_val_r2:.4f}\")\n",
    "        all_fold_best_r2.append(best_val_r2)\n",
    "        print(\"=============================\\n\")\n",
    "\n",
    "    # --- K-Fold 结束后，计算并打印平均 R2 ---\n",
    "    print(\"\\n--- K-Fold Cross-Validation Complete ---\")\n",
    "    print(f\"R2 scores for each fold: {all_fold_best_r2}\")\n",
    "    print(f\"Average R2: {np.mean(all_fold_best_r2):.4f}\")\n",
    "    print(f\"Std Dev R2: {np.std(all_fold_best_r2):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f608ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Train Teacher Model\")\n",
    "\n",
    "    parser.add_argument('--data_csv', type=str,\n",
    "                        default=os.path.join(project_root, 'outputs/datasets/train_processed.csv'),\n",
    "                        help='Path to the processed training CSV file')\n",
    "\n",
    "    parser.add_argument('--img_dir', type=str,\n",
    "                        default=os.path.join(project_root, 'csiro-biomass/train'),\n",
    "                        help='Path to the directory containing training images')\n",
    "\n",
    "    # 指定一个明确的输出目录\n",
    "    output_path = os.path.join(project_root, 'outputs/models/teacher_model_output')\n",
    "    parser.add_argument('--output_dir', type=str,\n",
    "                        default=output_path,\n",
    "                        help='Directory to save the best model')\n",
    "\n",
    "    # 训练超参数\n",
    "    parser.add_argument('--img_size', type=int, default=260, \n",
    "                        help='Image size for the model (B2 uses 260)')\n",
    "    parser.add_argument('--lr', type=float, default=5e-5,\n",
    "                        help='Initial learning rate (1e-4 is good for fine-tuning)')\n",
    "    parser.add_argument('--batch_size', type=int, default=16,\n",
    "                        help='Batch size (use 8 or 16 for small datasets)')\n",
    "    parser.add_argument('--epochs', type=int, default=150,\n",
    "                        help='Number of training epochs')\n",
    "    parser.add_argument('--val_split', type=float, default=0.2,\n",
    "                        help='Validation split fraction')\n",
    "    parser.add_argument('--num_workers', type=int, default=2,\n",
    "                        help='Number of workers for DataLoader')\n",
    "\n",
    "    # --- 早停参数 ---\n",
    "    parser.add_argument('--early_stopping_patience', type=int, default=15,\n",
    "                        help='Patience for early stopping (e.g., 15 epochs)')\n",
    "    # -------------------------\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "    print(f\"Model output will be saved to: {args.output_dir}\")\n",
    "    print(f\"Reading data from: {args.data_csv}\")\n",
    "\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 517845,
     "modelInstanceId": 502687,
     "sourceId": 664232,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 128.944148,
   "end_time": "2025-12-01T10:08:38.707084",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T10:06:29.762936",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
